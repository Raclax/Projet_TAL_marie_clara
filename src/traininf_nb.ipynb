{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import stanza\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouvrir les CSV et diviser train en train et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>titre</th>\n",
       "      <th>type</th>\n",
       "      <th>difficulte</th>\n",
       "      <th>cout</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>recette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recette_221358.xml</td>\n",
       "      <td>Feuilleté de saumon et de poireau, sauce aux c...</td>\n",
       "      <td>Plat principal</td>\n",
       "      <td>Facile</td>\n",
       "      <td>Moyen</td>\n",
       "      <td>- 1 gros pavé de saumon - 100 g de crevettes d...</td>\n",
       "      <td>Couper finement le blanc et un peu de vert des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recette_48656.xml</td>\n",
       "      <td>Cake poulet/moutarde/amandes</td>\n",
       "      <td>Entrée</td>\n",
       "      <td>Très facile</td>\n",
       "      <td>Bon marché</td>\n",
       "      <td>- 3 œufs - 150 g de farine - 1 sachet de levur...</td>\n",
       "      <td>Couper finement l'échalote, la faire revenir à...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recette_30049.xml</td>\n",
       "      <td>Bûche à la truite fumée (7ème rencontre)</td>\n",
       "      <td>Entrée</td>\n",
       "      <td>Moyennement difficile</td>\n",
       "      <td>Assez Cher</td>\n",
       "      <td>- 800 g de filet de truite saumonnée fumée en ...</td>\n",
       "      <td>Faites blanchir les épinards à l'eau bouillant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recette_71424.xml</td>\n",
       "      <td>Gâteau au yaourt au coco sans huile de laetitia</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>Très facile</td>\n",
       "      <td>Bon marché</td>\n",
       "      <td>- 1 pot de yaourt - 1 pot de lait de coco - 3 ...</td>\n",
       "      <td>Mélanger dans l'ordre tous les ingrédients en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recette_217204.xml</td>\n",
       "      <td>Crêpes au canard laqué</td>\n",
       "      <td>Entrée</td>\n",
       "      <td>Moyennement difficile</td>\n",
       "      <td>Moyen</td>\n",
       "      <td>- 90 g de farine - 45 g de maïzena - 2 œufs - ...</td>\n",
       "      <td>Fouetter les œufs avec l'eau, le lait et le su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12468</th>\n",
       "      <td>recette_88545.xml</td>\n",
       "      <td>Tarte thon et courgettes</td>\n",
       "      <td>Plat principal</td>\n",
       "      <td>Facile</td>\n",
       "      <td>Bon marché</td>\n",
       "      <td>- 1 pâte feuilleté - 2 œufs - 2 courgettes moy...</td>\n",
       "      <td>Couper les courgettes en fines rondelles, les ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12469</th>\n",
       "      <td>recette_36440.xml</td>\n",
       "      <td>Gratin de légumes à la viande</td>\n",
       "      <td>Plat principal</td>\n",
       "      <td>Facile</td>\n",
       "      <td>Bon marché</td>\n",
       "      <td>- 500 g de pommes de terre  - 400 g de carotte...</td>\n",
       "      <td>Epluchez les pommes de terre et lavez-les. Cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12470</th>\n",
       "      <td>recette_174633.xml</td>\n",
       "      <td>Tagliatelles fraiches au Montepulciano</td>\n",
       "      <td>Plat principal</td>\n",
       "      <td>Difficile</td>\n",
       "      <td>Moyen</td>\n",
       "      <td>- Pour les tagliatelles : - 150 g de semoule f...</td>\n",
       "      <td>Je conseille de préparer les tagliatelles la v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12471</th>\n",
       "      <td>recette_43030.xml</td>\n",
       "      <td>Bavarois praliné pistache, coeur de mousse au ...</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>Difficile</td>\n",
       "      <td>Assez Cher</td>\n",
       "      <td>- Pour le biscuit Dacquoise : - 160 g de blanc...</td>\n",
       "      <td>Petits commentaires :J'ai indiqué les recettes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12472</th>\n",
       "      <td>recette_56276.xml</td>\n",
       "      <td>Grand tralala au chocolat</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>Difficile</td>\n",
       "      <td>Moyen</td>\n",
       "      <td>- Pour la base craquante: - 60 g de crêpes den...</td>\n",
       "      <td>Faites fondre les 150 g de chocolat pour la fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12473 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   doc_id                                              titre  \\\n",
       "0      recette_221358.xml  Feuilleté de saumon et de poireau, sauce aux c...   \n",
       "1       recette_48656.xml                       Cake poulet/moutarde/amandes   \n",
       "2       recette_30049.xml           Bûche à la truite fumée (7ème rencontre)   \n",
       "3       recette_71424.xml    Gâteau au yaourt au coco sans huile de laetitia   \n",
       "4      recette_217204.xml                             Crêpes au canard laqué   \n",
       "...                   ...                                                ...   \n",
       "12468   recette_88545.xml                           Tarte thon et courgettes   \n",
       "12469   recette_36440.xml                      Gratin de légumes à la viande   \n",
       "12470  recette_174633.xml             Tagliatelles fraiches au Montepulciano   \n",
       "12471   recette_43030.xml  Bavarois praliné pistache, coeur de mousse au ...   \n",
       "12472   recette_56276.xml                          Grand tralala au chocolat   \n",
       "\n",
       "                 type             difficulte        cout  \\\n",
       "0      Plat principal                 Facile       Moyen   \n",
       "1              Entrée            Très facile  Bon marché   \n",
       "2              Entrée  Moyennement difficile  Assez Cher   \n",
       "3             Dessert            Très facile  Bon marché   \n",
       "4              Entrée  Moyennement difficile       Moyen   \n",
       "...               ...                    ...         ...   \n",
       "12468  Plat principal                 Facile  Bon marché   \n",
       "12469  Plat principal                 Facile  Bon marché   \n",
       "12470  Plat principal              Difficile       Moyen   \n",
       "12471         Dessert              Difficile  Assez Cher   \n",
       "12472         Dessert              Difficile       Moyen   \n",
       "\n",
       "                                             ingredients  \\\n",
       "0      - 1 gros pavé de saumon - 100 g de crevettes d...   \n",
       "1      - 3 œufs - 150 g de farine - 1 sachet de levur...   \n",
       "2      - 800 g de filet de truite saumonnée fumée en ...   \n",
       "3      - 1 pot de yaourt - 1 pot de lait de coco - 3 ...   \n",
       "4      - 90 g de farine - 45 g de maïzena - 2 œufs - ...   \n",
       "...                                                  ...   \n",
       "12468  - 1 pâte feuilleté - 2 œufs - 2 courgettes moy...   \n",
       "12469  - 500 g de pommes de terre  - 400 g de carotte...   \n",
       "12470  - Pour les tagliatelles : - 150 g de semoule f...   \n",
       "12471  - Pour le biscuit Dacquoise : - 160 g de blanc...   \n",
       "12472  - Pour la base craquante: - 60 g de crêpes den...   \n",
       "\n",
       "                                                 recette  \n",
       "0      Couper finement le blanc et un peu de vert des...  \n",
       "1      Couper finement l'échalote, la faire revenir à...  \n",
       "2      Faites blanchir les épinards à l'eau bouillant...  \n",
       "3      Mélanger dans l'ordre tous les ingrédients en ...  \n",
       "4      Fouetter les œufs avec l'eau, le lait et le su...  \n",
       "...                                                  ...  \n",
       "12468  Couper les courgettes en fines rondelles, les ...  \n",
       "12469  Epluchez les pommes de terre et lavez-les. Cou...  \n",
       "12470  Je conseille de préparer les tagliatelles la v...  \n",
       "12471  Petits commentaires :J'ai indiqué les recettes...  \n",
       "12472  Faites fondre les 150 g de chocolat pour la fe...  \n",
       "\n",
       "[12473 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(df_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../data/train1.csv\", index=False)\n",
    "validation.to_csv(\"../data/validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 13:55:56 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 21.0MB/s]                    \n",
      "2025-03-03 13:55:56 INFO: Downloaded file to /home/raclax/stanza_resources/resources.json\n",
      "2025-03-03 13:55:56 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-03-03 13:55:56 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2025-03-03 13:55:56 INFO: Using device: cpu\n",
      "2025-03-03 13:55:56 INFO: Loading: tokenize\n",
      "2025-03-03 13:55:56 INFO: Loading: mwt\n",
      "2025-03-03 13:55:56 INFO: Loading: lemma\n",
      "2025-03-03 13:55:57 INFO: Done loading processors!\n",
      "/tmp/ipykernel_23383/3500904215.py:15: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_train[\"recette\"][i] = df_train[\"recette\"][i].lower()\n",
      "/tmp/ipykernel_23383/3500904215.py:16: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_train[\"recette\"][i] = lemmatize(df_train[\"recette\"][i])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_train)):\n\u001b[32m     15\u001b[39m     df_train[\u001b[33m\"\u001b[39m\u001b[33mrecette\u001b[39m\u001b[33m\"\u001b[39m][i] = df_train[\u001b[33m\"\u001b[39m\u001b[33mrecette\u001b[39m\u001b[33m\"\u001b[39m][i].lower()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     df_train[\u001b[33m\"\u001b[39m\u001b[33mrecette\u001b[39m\u001b[33m\"\u001b[39m][i] = \u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecette\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# df_train[\"recette\"] = df_train[\"recette\"].apply(lambda x: x.lower())\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# df_train[\"recette\"] = lemmatize(df_train[\"recette\"])\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# df_train[\"recette\"] = stem(df_train[\"recette\"])\u001b[39;00m\n\u001b[32m     23\u001b[39m df_train.to_csv(\u001b[33m\"\u001b[39m\u001b[33m../data/train_pre.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mlemmatize\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlemmatize\u001b[39m(text):\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     doc = \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     lemmas = [\n\u001b[32m      6\u001b[39m         word.lemma\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m doc.sentences\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence.words\n\u001b[32m      9\u001b[39m     ]\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(lemmas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/stanza/pipeline/core.py:480\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, doc, processors)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc, processors=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/stanza/pipeline/core.py:431\u001b[39m, in \u001b[36mPipeline.process\u001b[39m\u001b[34m(self, doc, processors)\u001b[39m\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.processors.get(processor_name):\n\u001b[32m    430\u001b[39m         process = \u001b[38;5;28mself\u001b[39m.processors[processor_name].bulk_process \u001b[38;5;28;01mif\u001b[39;00m bulk \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.processors[processor_name].process\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m         doc = \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/stanza/pipeline/tokenize_processor.py:104\u001b[39m, in \u001b[36mTokenizeProcessor.process\u001b[39m\u001b[34m(self, document)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# get dict data\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     _, _, _, document = \u001b[43moutput_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m                                           \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m                                           \u001b[49m\u001b[43morig_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m                                           \u001b[49m\u001b[43mno_ssplit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mno_ssplit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m                                           \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_workers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m                                           \u001b[49m\u001b[43mpostprocessor\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_postprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# replace excessively long tokens with <UNK> to avoid downstream GPU memory issues in POS\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m document:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/stanza/models/tokenization/utils.py:324\u001b[39m, in \u001b[36moutput_predictions\u001b[39m\u001b[34m(output_file, trainer, data_generator, vocab, mwt_dict, max_seqlen, orig_text, no_ssplit, use_regex_tokens, num_workers, postprocessor)\u001b[39m\n\u001b[32m    321\u001b[39m batch_size = trainer.args[\u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    322\u001b[39m max_seqlen = \u001b[38;5;28mmax\u001b[39m(\u001b[32m1000\u001b[39m, max_seqlen)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m all_preds, all_raw = \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seqlen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_regex_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m use_la_ittb_shorthand = trainer.args[\u001b[33m'\u001b[39m\u001b[33mshorthand\u001b[39m\u001b[33m'\u001b[39m] == \u001b[33m'\u001b[39m\u001b[33mla_ittb\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    327\u001b[39m skip_newline = trainer.args[\u001b[33m'\u001b[39m\u001b[33mskip_newline\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/stanza/models/tokenization/utils.py:266\u001b[39m, in \u001b[36mpredict\u001b[39m\u001b[34m(trainer, data_generator, batch_size, max_seqlen, use_regex_tokens, num_workers)\u001b[39m\n\u001b[32m    263\u001b[39m     all_raw.append(\u001b[38;5;28mlist\u001b[39m(paragraph))\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m N <= max_seqlen:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     pred = np.argmax(\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m2\u001b[39m)\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    268\u001b[39m     \u001b[38;5;66;03m# TODO: we could shortcircuit some processing of\u001b[39;00m\n\u001b[32m    269\u001b[39m     \u001b[38;5;66;03m# long strings of PAD by tracking which rows are finished\u001b[39;00m\n\u001b[32m    270\u001b[39m     idx = [\u001b[32m0\u001b[39m] * num_sentences\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/stanza/models/tokenization/trainer.py:63\u001b[39m, in \u001b[36mTrainer.predict\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m     60\u001b[39m units = units.to(device)\n\u001b[32m     61\u001b[39m features = features.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pred.data.cpu().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/stanza/models/tokenization/model.py:77\u001b[39m, in \u001b[36mTokenizer.forward\u001b[39m\u001b[34m(self, x, feats)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args[\u001b[33m'\u001b[39m\u001b[33mhierarchical\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args[\u001b[33m'\u001b[39m\u001b[33mhier_invtemp\u001b[39m\u001b[33m'\u001b[39m] > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m         inp2, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrnn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoknoise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mtok0\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhier_invtemp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     79\u001b[39m         inp2, _ = \u001b[38;5;28mself\u001b[39m.rnn2(inp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/M12/S2/TAL/praat/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize,lemma\")\n",
    "    \n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [\n",
    "        word.lemma\n",
    "        for sentence in doc.sentences\n",
    "        for word in sentence.words\n",
    "    ]\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "\n",
    "# faire une boucle pour ne prendre qu'une recette à la fois\n",
    "for i in range(len(df_train)):\n",
    "    df_train[\"recette\"][i] = df_train[\"recette\"][i].lower()\n",
    "    df_train[\"recette\"][i] = lemmatize(df_train[\"recette\"][i])\n",
    "    \n",
    "df_train.to_csv(\"../data/train_pre.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline (random?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(matrix, classes):\n",
    "    dt_classifier = DecisionTreeClassifier()\n",
    "    y_pred = cross_val_predict(dt_classifier, matrix, classes, cv=10)\n",
    "    return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(matrix, classes):\n",
    "    svm_classifier = SVC(kernel='linear')\n",
    "    y_pred = cross_val_predict(svm_classifier, matrix, classes, cv=10)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(matrix, classes):\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "    y_pred = cross_val_predict(rf_classifier, matrix, classes, cv=10)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(matrix, classes):\n",
    "    nb_classifier = MultinomialNB()\n",
    "    y_pred = cross_val_predict(nb_classifier, matrix, classes, cv=10)\n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
